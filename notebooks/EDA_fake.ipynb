{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c637674e-2eab-4558-a745-9da60bd27cc1",
   "metadata": {},
   "source": [
    "# 1. Borrower_profile: Hồ sơ người vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1de7e7-bb44-4868-92bd-1ef212abed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, mean, when, round as spark_round, isnan, desc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9a78b3-2e5c-498f-86b2-d6c52b2f7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"EDA_BorrowerProfile\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef6edcd-615c-4cf6-9637-235d509d1d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o32.csv.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (172.18.0.7 executor 0): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Zero blocklocations for /bigdata/data/splitted_data/borrower_profile/part-00001-2529e835-f92b-482e-afe0-37078b3cfaf4-c000.csv. Name node is in safe mode.\nThe reported blocks 0 needs additional 169 blocks to reach the threshold 0.9990 of total blocks 170.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1960)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:755)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:439)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1519)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1416)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n\tat com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:333)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy17.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:892)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:881)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:870)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1038)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:339)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:335)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:352)\n\tat org.apache.hadoop.fs.FileSystem.lambda$openFileWithOptions$0(FileSystem.java:4633)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.FileSystem.openFileWithOptions(FileSystem.java:4631)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.text.TextFileFormat.$anonfun$readToUnsafeMem$1(TextFileFormat.scala:119)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:148)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:112)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:63)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:210)\n\tat scala.Option.orElse(Option.scala:447)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:207)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:411)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:571)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Zero blocklocations for /bigdata/data/splitted_data/borrower_profile/part-00001-2529e835-f92b-482e-afe0-37078b3cfaf4-c000.csv. Name node is in safe mode.\nThe reported blocks 0 needs additional 169 blocks to reach the threshold 0.9990 of total blocks 170.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1960)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:755)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:439)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1519)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1416)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n\tat com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:333)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy17.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:892)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:881)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:870)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1038)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:339)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:335)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:352)\n\tat org.apache.hadoop.fs.FileSystem.lambda$openFileWithOptions$0(FileSystem.java:4633)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.FileSystem.openFileWithOptions(FileSystem.java:4631)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.text.TextFileFormat.$anonfun$readToUnsafeMem$1(TextFileFormat.scala:119)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:148)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m borrower_profile_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://namenode:9000/bigdata/data/splitted_data/borrower_profile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m borrower_profile_df\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:410\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    408\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o32.csv.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3) (172.18.0.7 executor 0): org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Zero blocklocations for /bigdata/data/splitted_data/borrower_profile/part-00001-2529e835-f92b-482e-afe0-37078b3cfaf4-c000.csv. Name node is in safe mode.\nThe reported blocks 0 needs additional 169 blocks to reach the threshold 0.9990 of total blocks 170.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1960)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:755)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:439)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1519)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1416)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n\tat com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:333)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy17.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:892)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:881)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:870)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1038)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:339)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:335)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:352)\n\tat org.apache.hadoop.fs.FileSystem.lambda$openFileWithOptions$0(FileSystem.java:4633)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.FileSystem.openFileWithOptions(FileSystem.java:4631)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.text.TextFileFormat.$anonfun$readToUnsafeMem$1(TextFileFormat.scala:119)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:148)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:112)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:63)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:210)\n\tat scala.Option.orElse(Option.scala:447)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:207)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:411)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:571)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Zero blocklocations for /bigdata/data/splitted_data/borrower_profile/part-00001-2529e835-f92b-482e-afe0-37078b3cfaf4-c000.csv. Name node is in safe mode.\nThe reported blocks 0 needs additional 169 blocks to reach the threshold 0.9990 of total blocks 170.\nThe minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:namenode\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1476)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1960)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:755)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:439)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)\n\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1519)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1416)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n\tat com.sun.proxy.$Proxy16.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:333)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n\tat com.sun.proxy.$Proxy17.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:892)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:881)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:870)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1038)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:339)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:335)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:352)\n\tat org.apache.hadoop.fs.FileSystem.lambda$openFileWithOptions$0(FileSystem.java:4633)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.FileSystem.openFileWithOptions(FileSystem.java:4631)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.text.TextFileFormat.$anonfun$readToUnsafeMem$1(TextFileFormat.scala:119)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:148)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:133)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:187)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:104)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "borrower_profile_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .csv(\"hdfs://namenode:9000/bigdata/data/splitted_data/borrower_profile\")\n",
    ")\n",
    "borrower_profile_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c014e6-3e48-4d1b-8c20-509412504a40",
   "metadata": {},
   "source": [
    "## Thống kê mô tả cơ bản cho thu nhập hàng năm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22ea45-bbad-4411-bc1f-493087135000",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats = borrower_profile_df.select(\"annual_inc\").describe()\n",
    "numeric_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f53029-2aa9-46c7-8288-fe30bc372699",
   "metadata": {},
   "source": [
    "## Một số thống kê quan trọng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf3ec1-f3ba-49a4-a5e4-a96b6bf84726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(col_name, top_n=15):\n",
    "    print(f\"\\n=== Frequency: {col_name} ===\")\n",
    "    borrower_profile_df.groupBy(col_name).count().orderBy(desc(\"count\")).show(top_n, truncate=False)\n",
    "\n",
    "for col_name in [\"emp_title\", \"emp_length\", \"home_ownership\", \"verification_status\", \"addr_state\", \"zip_code\"]:\n",
    "    if col_name in borrower_profile_df.columns:\n",
    "        freq_table(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b5250-4149-44bf-9673-57aa882c9af7",
   "metadata": {},
   "source": [
    "## Tỷ lệ các giá trị unique ở 3 cột emp_length, home_ownership, verification_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9227e1a-e952-4a29-b8d9-ad40490f2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"emp_length\", \"home_ownership\", \"verification_status\"]\n",
    "\n",
    "total_rows = borrower_profile_df.count()\n",
    "\n",
    "combined = pd.DataFrame()\n",
    "for c in cols:\n",
    "    temp = (\n",
    "        borrower_profile_df.groupBy(c)\n",
    "          .agg(count(\"*\").alias(\"count\"))\n",
    "          .withColumn(\"pct\", (col(\"count\") / total_rows) * 100)\n",
    "          .orderBy(col(\"pct\").desc())\n",
    "          .toPandas()\n",
    "    )\n",
    "    temp[\"column\"] = c\n",
    "    temp = temp.rename(columns={c: \"value\"})\n",
    "    combined = pd.concat([combined, temp[[\"column\", \"value\", \"pct\"]]], ignore_index=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5), sharey=True)\n",
    "\n",
    "for i, c in enumerate(cols):\n",
    "    borrower_profile_df_sub = combined[combined[\"column\"] == c].copy()\n",
    "    borrower_profile_df_sub = borrower_profile_df_sub.sort_values(\"pct\", ascending=True)  # để thứ tự đẹp hơn\n",
    "\n",
    "    left = 0\n",
    "    for _, row in borrower_profile_df_sub.iterrows():\n",
    "        axes[i].barh([c], row[\"pct\"], left=left, label=row[\"value\"])\n",
    "        left += row[\"pct\"]\n",
    "\n",
    "    # Trang trí từng subplot\n",
    "    axes[i].set_title(f\"{c}\")\n",
    "    axes[i].set_xlim(0, 100)\n",
    "    axes[i].set_xlabel(\"Tỷ lệ (%)\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "    axes[i].legend(title=\"Giá trị\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.suptitle(\"Phân bố tỷ lệ (%) của các giá trị trong 3 trường dữ liệu\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44da0d4-a2dc-4897-a6dc-02070a574c60",
   "metadata": {},
   "source": [
    "## Trung bình thu nhập theo các nhóm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714e88c-0467-478b-bfa0-ac85a03d01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"home_ownership\" in borrower_profile_df.columns and \"annual_inc\" in borrower_profile_df.columns:\n",
    "    avg_by_home = borrower_profile_df.groupBy(\"home_ownership\").agg(spark_round(mean(\"annual_inc\"), 2).alias(\"avg_income\"))\n",
    "    print(\"\\n=== Average income by home_ownership ===\")\n",
    "    avg_by_home.show()\n",
    "\n",
    "if \"verification_status\" in borrower_profile_df.columns and \"annual_inc\" in borrower_profile_df.columns:\n",
    "    avg_by_verif = borrower_profile_df.groupBy(\"verification_status\").agg(spark_round(mean(\"annual_inc\"), 2).alias(\"avg_income\"))\n",
    "    print(\"\\n=== Average income by verification_status ===\")\n",
    "    avg_by_verif.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd9189-17fb-491c-a6a8-92ebb8135b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "income_pd = borrower_profile_df.select(\"annual_inc\").dropna().toPandas()\n",
    "income_pd = income_pd[income_pd[\"annual_inc\"] < 300000] \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(income_pd[\"annual_inc\"], bins=50, kde=True)\n",
    "plt.title(\"Phân bố thu nhập hàng năm (annual_inc)\")\n",
    "plt.xlabel(\"Annual Income (USD)\")\n",
    "plt.ylabel(\"Số lượng người vay\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a55c8-cc4b-431a-a3ff-ba019d709489",
   "metadata": {},
   "source": [
    "## Phân bố loại sở hữu nhà (Home Ownership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18ba7b-44c1-4b2f-af73-d2092a661e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_borrower_profile_df = borrower_profile_df.groupBy(\"home_ownership\").count().orderBy(\"count\", ascending=False)\n",
    "home_pd = home_borrower_profile_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.barplot(\n",
    "    x=\"home_ownership\", \n",
    "    y=\"count\", \n",
    "    hue=\"home_ownership\",\n",
    "    data=home_pd, \n",
    "    palette=\"pastel\", \n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Thêm nhãn số trên từng cột\n",
    "for p in ax.patches:\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2,\n",
    "        p.get_height() + home_pd[\"count\"].max() * 0.005,\n",
    "        f\"{int(p.get_height()):,}\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Phân bố loại sở hữu nhà (Home Ownership)\")\n",
    "plt.xlabel(\"Loại sở hữu nhà\")\n",
    "plt.ylabel(\"Số lượng người vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f1eb2-521f-44da-ab90-0ba24cfc41d3",
   "metadata": {},
   "source": [
    "## Phân bố tình trạng xác minh thu nhập (Verification Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcdb01-b7d9-4476-a918-65f204dc222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_pd = borrower_profile_df.groupBy(\"verification_status\").count().orderBy(desc(\"count\")).toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    x=\"verification_status\",\n",
    "    y=\"count\",\n",
    "    hue=\"verification_status\",\n",
    "    data=verif_pd,\n",
    "    palette=\"Set2\",\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.title(\"Phân bố tình trạng xác minh thu nhập (Verification Status)\")\n",
    "plt.xlabel(\"Tình trạng xác minh thu nhập\")\n",
    "plt.ylabel(\"Số lượng người vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0460a-e885-4061-9628-607a2c821889",
   "metadata": {},
   "source": [
    "## Phân bố thời gian làm việc của người vay (Emp Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bafc26-cd88-4517-9672-b147d1041c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_pd = borrower_profile_df.groupBy(\"emp_length\").count().toPandas()\n",
    "\n",
    "order = [\n",
    "    \"< 1 year\", \"1 year\", \"2 years\", \"3 years\", \"4 years\",\n",
    "    \"5 years\", \"6 years\", \"7 years\", \"8 years\", \"9 years\", \"10+ years\"\n",
    "]\n",
    "\n",
    "emp_pd = emp_pd[emp_pd[\"emp_length\"].isin(order)]\n",
    "emp_pd[\"emp_length\"] = pd.Categorical(emp_pd[\"emp_length\"], categories=order, ordered=True)\n",
    "emp_pd = emp_pd.sort_values(\"emp_length\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(\n",
    "    y=\"emp_length\",\n",
    "    x=\"count\",\n",
    "    hue=\"emp_length\",\n",
    "    data=emp_pd,\n",
    "    palette=\"muted\",\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    ax.text(\n",
    "        width + emp_pd[\"count\"].max() * 0.01, \n",
    "        p.get_y() + p.get_height() / 2,\n",
    "        f\"{int(width):,}\",                   \n",
    "        va=\"center\", ha=\"left\", fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Phân bố thời gian làm việc của người vay (Emp Length)\")\n",
    "plt.xlabel(\"Số lượng người vay\")\n",
    "plt.ylabel(\"Khoảng thời gian làm việc\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322bc4e-6cc6-401f-b486-6ad0ff7e094f",
   "metadata": {},
   "source": [
    "## Top 10 bang/khu vực có nhiều người vay nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa4562-5529-4e26-ad7c-dfbfe139dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pd = (\n",
    "    borrower_profile_df.groupBy(\"addr_state\")\n",
    "      .count()\n",
    "      .orderBy(desc(\"count\"))\n",
    "      .limit(10)\n",
    "      .toPandas()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(\n",
    "    x=\"addr_state\",\n",
    "    y=\"count\",\n",
    "    data=state_pd,\n",
    "    hue=\"addr_state\",\n",
    "    palette=\"crest\",\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# --- Thêm nhãn số trên đầu cột ---\n",
    "for p in ax.patches:\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2,\n",
    "        p.get_height() + state_pd[\"count\"].max() * 0.01, \n",
    "        f\"{int(p.get_height()):,}\",\n",
    "        ha=\"center\", va=\"bottom\", fontsize=10\n",
    "    )\n",
    "\n",
    "# --- Hoàn thiện biểu đồ ---\n",
    "plt.title(\"Top 10 bang/khu vực có nhiều người vay nhất\")\n",
    "plt.xlabel(\"Bang / Khu vực\")\n",
    "plt.ylabel(\"Số lượng người vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fe714-36dd-4cc2-9bda-a35c1a308c0a",
   "metadata": {},
   "source": [
    "# 2. Loan_info: Thông tin khoản vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03640cab-5406-4114-9ef5-d364e9cb0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"EDA_LoanInfo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e637b3d-9eea-41b4-bdbc-1d0ff21b543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = spark.read.csv(\"hdfs://namenode:9000/bigdata/data/splitted_data/loan_info\", header=True, inferSchema=True)\n",
    "p_loan_df = loan_df.toPandas()\n",
    "loan_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af4fda-faf2-425b-bc20-96b188fdbfd5",
   "metadata": {},
   "source": [
    "## Thống kê mô tả tổng quát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e0478-f648-4c73-8dc6-5ca7677e04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.describe([\"loan_amnt\", \"funded_amnt\", \"funded_amnt_inv\", \"int_rate\", \"installment\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed462b-f8af-4fc2-a3b0-9cf63f8a35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def hist_with_numbers(series, title, xlabel):\n",
    "    plt.figure(figsize=(20,6))\n",
    "    ax = sns.histplot(series, bins=50, kde=True)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        height = int(p.get_height())\n",
    "        if height > 0:\n",
    "            ax.annotate(\n",
    "                str(height),\n",
    "                (p.get_x() + p.get_width()/2, height),\n",
    "                ha='center', va='bottom', fontsize=8\n",
    "            )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Số lượng (count)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194c6c3-58bd-449a-85a1-438ceec5d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_with_numbers(\n",
    "    p_loan_df[\"loan_amnt\"],\n",
    "    \"Phân bố số tiền vay (loan_amnt)\",\n",
    "    \"Số tiền vay ($)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd17902-e01f-4e29-b1b4-76e91f16c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_with_numbers(\n",
    "    p_loan_df[\"funded_amnt\"],\n",
    "    \"Phân bố số tiền được duyệt (funded_amnt)\",\n",
    "    \"funded_amnt ($)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23569a96-5547-423e-8a6b-abbe48527a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_with_numbers(\n",
    "    p_loan_df[\"funded_amnt_inv\"],\n",
    "    \"Phân bố số tiền nhà đầu tư cấp vốn (funded_amnt_inv)\",\n",
    "    \"funded_amnt_inv ($)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d93d62-567d-4675-8b42-f4d0307215fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_with_numbers(\n",
    "    p_loan_df[\"int_rate\"],\n",
    "    \"Phân bố lãi suất (int_rate)\",\n",
    "    \"Lãi suất (%)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948ff67-c78b-4b61-a63b-4987f2bff41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_with_numbers(\n",
    "    p_loan_df[\"installment\"],\n",
    "    \"Phân bố khoản trả hàng tháng (installment)\",\n",
    "    \"installment ($)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52c034-3120-4bac-b561-cbdf611ba481",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.withColumn(\"funded_ratio\", col(\"funded_amnt\") / col(\"loan_amnt\"))\n",
    "loan_df.select(avg(\"funded_ratio\")).show()\n",
    "p_loan_df = loan_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.histplot(p_loan_df[\"funded_ratio\"], bins=100, kde=True, color=\"skyblue\")\n",
    "plt.xlim(0.95, 1.01)\n",
    "plt.title(\"Phân phối tỷ lệ tài trợ\")\n",
    "plt.xlabel(\"Tỷ lệ tài trợ\")\n",
    "plt.ylabel(\"Số khoản vay\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66db0c0-8f29-4c4a-9d24-df86968bf827",
   "metadata": {},
   "source": [
    "## Thống kê theo thời hạn vay (term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c483b3-86a4-4023-8e9d-d376b362151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.groupBy(\"term\").count().orderBy(\"count\", ascending=False).show()\n",
    "term_pd = loan_df.groupBy(\"term\").count().toPandas()\n",
    "total = term_pd[\"count\"].sum()\n",
    "term_pd[\"pct\"] = term_pd[\"count\"] / total\n",
    "plt.figure(figsize=(4,6))\n",
    "\n",
    "plt.bar(\n",
    "    x=[\"term\"], \n",
    "    height=term_pd.loc[term_pd[\"term\"]==\"36 months\", \"pct\"], \n",
    "    label=\"36 months\"\n",
    ")\n",
    "plt.bar(\n",
    "    x=[\"term\"], \n",
    "    height=term_pd.loc[term_pd[\"term\"]==\"60 months\", \"pct\"], \n",
    "    bottom=term_pd.loc[term_pd[\"term\"]==\"36 months\", \"pct\"], \n",
    "    label=\"60 months\"\n",
    ")\n",
    "\n",
    "bottom = 0\n",
    "for i, row in term_pd.iterrows():\n",
    "    plt.text(\n",
    "        0, \n",
    "        bottom + row[\"pct\"]/2, \n",
    "        f\"{row['pct']*100:.2f}%\", \n",
    "        ha=\"center\", \n",
    "        va=\"center\", \n",
    "        color=\"white\", \n",
    "        fontweight=\"bold\"\n",
    "    )\n",
    "    bottom += row[\"pct\"]\n",
    "\n",
    "plt.ylabel(\"Tỷ lệ (%)\")\n",
    "plt.title(\"Phân bố thời hạn khoản vay (term)\")\n",
    "plt.legend(title=\"Term\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707cb11-b287-45f5-9907-88e1b8d291c4",
   "metadata": {},
   "source": [
    "## Thống kê theo hạng tín dụng (grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134283f7-67e2-468c-982f-9268a67c7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.groupBy(\"grade\").count().orderBy(\"grade\").show()\n",
    "grade_pd = loan_df.groupBy(\"grade\").count().orderBy(\"grade\").toPandas()\n",
    "\n",
    "# Tính phần trăm\n",
    "total = grade_pd[\"count\"].sum()\n",
    "grade_pd[\"pct\"] = grade_pd[\"count\"] / total\n",
    "\n",
    "# Vẽ stacked bar\n",
    "plt.figure(figsize=(6,6))\n",
    "bottom = 0\n",
    "colors = plt.cm.tab20.colors \n",
    "\n",
    "for i, row in grade_pd.iterrows():\n",
    "    plt.bar(\n",
    "        x=[\"grade\"], \n",
    "        height=row[\"pct\"], \n",
    "        bottom=bottom, \n",
    "        label=row[\"grade\"], \n",
    "        color=colors[i % len(colors)]\n",
    "    )\n",
    "    # Ghi % ở giữa từng phần\n",
    "    plt.text(\n",
    "        0, \n",
    "        bottom + row[\"pct\"]/2, \n",
    "        f\"{row['pct']*100:.2f}%\", \n",
    "        ha=\"center\", va=\"center\", color=\"white\", fontweight=\"bold\"\n",
    "    )\n",
    "    bottom += row[\"pct\"]\n",
    "\n",
    "plt.title(\"Phân bố hạng tín dụng (grade) theo tỷ lệ %\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Tỷ lệ (%)\")\n",
    "plt.legend(title=\"Grade\", bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e464c-9bbd-4945-ad71-67ea570d06f7",
   "metadata": {},
   "source": [
    "## Phân bố mục đích vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef49936-05ed-4b8e-8d3d-f42e402fc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_purpose = loan_df.groupBy(\"purpose\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"loan_amnt\").alias(\"avg_loan\"),\n",
    "    avg(\"int_rate\").alias(\"avg_interest\")\n",
    ").orderBy(col(\"count\").desc())\n",
    "loan_purpose.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95244ee-8403-4fcb-a84f-a2bc53f79616",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loan_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6077fd6-132b-4d9b-8570-c176626d30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_purpose = p_loan_df[\"purpose\"].value_counts().head(10).reset_index()\n",
    "top10_purpose.columns = [\"purpose\", \"count\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    y=\"purpose\",\n",
    "    x=\"count\",\n",
    "    hue=\"purpose\",\n",
    "    data=top10_purpose,\n",
    "    palette=\"mako\",\n",
    "    dodge=False \n",
    ")\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "# Thêm số phía sau bar\n",
    "for index, row in top10_purpose.iterrows():\n",
    "    plt.text(\n",
    "        row[\"count\"] + 5000,\n",
    "        index,\n",
    "        str(row[\"count\"]),\n",
    "        va='center'\n",
    "    )\n",
    "\n",
    "plt.title(\"Top 10 mục đích vay phổ biến nhất\")\n",
    "plt.xlabel(\"Số lượng khoản vay\")\n",
    "plt.ylabel(\"Mục đích vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b5ca9-709c-4ff3-93ed-7413cb5f978c",
   "metadata": {},
   "source": [
    "## Lãi suất trung bình theo hạng tín dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a550f7b-fe8c-42e6-b319-4ba8476ac98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rate_by_grade = loan_df.groupBy(\"grade\").agg(avg(\"int_rate\").alias(\"avg_interest\")).orderBy(\"grade\")\n",
    "avg_rate_by_grade.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ee06f-dd6d-493f-9f97-2053d492b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "mean_int_rate = p_loan_df.groupby(\"grade\")[\"int_rate\"].mean().reset_index()\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"grade\",\n",
    "    y=\"int_rate\",\n",
    "    hue=\"grade\",\n",
    "    data=mean_int_rate,\n",
    "    palette=\"Set2\",\n",
    "    dodge=False\n",
    ")\n",
    "plt.legend([],[], frameon=False)  \n",
    "\n",
    "for index, row in mean_int_rate.iterrows():\n",
    "    plt.text(\n",
    "        index,       \n",
    "        row[\"int_rate\"] + 0.1, \n",
    "        f\"{row['int_rate']:.2f}\",\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Lãi suất trung bình theo hạng tín dụng (grade)\")\n",
    "plt.xlabel(\"Hạng tín dụng\")\n",
    "plt.ylabel(\"Lãi suất trung bình (%)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68237814-6ba5-4071-882f-419715010982",
   "metadata": {},
   "source": [
    "## Lãi suất trung bình theo thời hạn vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d6089-ed89-4861-9354-584ebb65b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rate_by_term = loan_df.groupBy(\"term\").agg(avg(\"int_rate\").alias(\"avg_interest\")).orderBy(\"term\")\n",
    "avg_rate_by_term.show()\n",
    "avg_rate_by_term = avg_rate_by_term.toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(\n",
    "    x=\"term\", \n",
    "    y=\"avg_interest\", \n",
    "    hue=\"term\",\n",
    "    data=avg_rate_by_term, \n",
    "    palette=\"pastel\",\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.title(\"Lãi suất trung bình theo kỳ hạn vay\")\n",
    "plt.xlabel(\"Kỳ hạn vay\")\n",
    "plt.ylabel(\"Lãi suất trung bình (%)\")\n",
    "\n",
    "# Thêm giá trị trên mỗi cột\n",
    "for index, row in avg_rate_by_term.iterrows():\n",
    "    plt.text(index, row.avg_interest + 0.2, f\"{row.avg_interest:.2f}%\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fc3fd-f746-4aea-b1d4-4e8df0b96397",
   "metadata": {},
   "source": [
    "## Tỷ lệ tài trợ thực tế (funded_amnt / loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f906cd-5bd3-4f12-a0d6-9243dc308379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "loan_df = loan_df.withColumn(\"funded_ratio\", col(\"funded_amnt\") / col(\"loan_amnt\"))\n",
    "p_loan_df = loan_df.toPandas()\n",
    "\n",
    "p_loan_df[\"funded_ratio_bin\"] = pd.cut(p_loan_df[\"funded_ratio\"], bins=20)\n",
    "\n",
    "df_plot = p_loan_df[\"funded_ratio_bin\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "bars = plt.bar(df_plot.index.astype(str), df_plot.values)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Phân phối funded_ratio\")\n",
    "plt.xlabel(\"funded_ratio (bin)\")\n",
    "plt.ylabel(\"Số khoản vay\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x()+bar.get_width()/2, height,\n",
    "             str(height), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcadbf8-cc94-4935-8701-c32ba19d0125",
   "metadata": {},
   "source": [
    "## Tỷ lệ số tiền phải trả mỗi kỳ so với khoản vay (installment / loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d4a74-1b8f-4baf-8ef0-450acb3963cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.withColumn(\n",
    "    \"installment_to_loan_ratio\",\n",
    "    col(\"installment\") / col(\"loan_amnt\")\n",
    ")\n",
    "p_loan_df = loan_df.toPandas()\n",
    "\n",
    "p_loan_df[\"install_ratio_bin\"] = pd.cut(\n",
    "    p_loan_df[\"installment_to_loan_ratio\"], bins=20\n",
    ")\n",
    "\n",
    "df_plot = p_loan_df[\"install_ratio_bin\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "bars = plt.bar(df_plot.index.astype(str), df_plot.values)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Phân phối installment_to_loan_ratio\")\n",
    "plt.xlabel(\"installment_to_loan_ratio (bin)\")\n",
    "plt.ylabel(\"Số khoản vay\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x()+bar.get_width()/2, height,\n",
    "             str(height), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e87b87-aafd-4a55-8b8f-5d49113fe3d1",
   "metadata": {},
   "source": [
    "## Số tiền lãi phải trả mỗi kỳ (installment−loan_amnt/term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f04f8-9479-4e8d-a0a4-61475f646cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.withColumn(\n",
    "    \"interest_amount\",\n",
    "    col(\"loan_amnt\") * (col(\"int_rate\") / 100)\n",
    ")\n",
    "\n",
    "p_loan_df = loan_df.toPandas()\n",
    "\n",
    "p_loan_df[\"interest_amount_bin\"] = pd.cut(p_loan_df[\"interest_amount\"], bins=20)\n",
    "\n",
    "df_plot = p_loan_df[\"interest_amount_bin\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "bars = plt.bar(df_plot.index.astype(str), df_plot.values)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Phân phối interest_amount\")\n",
    "plt.xlabel(\"interest_amount (bin)\")\n",
    "plt.ylabel(\"Số khoản vay\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x()+bar.get_width()/2, height,\n",
    "             str(height), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13a54e-ce48-4f38-a7a3-6e611627a9ee",
   "metadata": {},
   "source": [
    "# 3. Loan status history: Lịch sử trạng thái khoản vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98233fd-1955-452a-a0e0-e243db7fd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"LoanStatusAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85d09e-8faf-484f-8ed4-4ccab8b3a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://namenode:9000/bigdata/data/splitted_data/loan_status_history\"\n",
    "\n",
    "loan_status_history_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .csv(path)\n",
    ")\n",
    "\n",
    "loan_status_history_df.printSchema()\n",
    "loan_status_history_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5cd7b-6e4e-4338-880f-3dc846c48356",
   "metadata": {},
   "source": [
    "## Thống kê trạng thái khoản vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afc3b7-8f35-474f-8883-6ded17c12330",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = (\n",
    "    loan_status_history_df.groupBy(\"loan_status\")\n",
    "      .agg(count(\"*\").alias(\"count\"))\n",
    "      .orderBy(col(\"count\").desc())\n",
    ")\n",
    "status_counts.show()\n",
    "status_counts_pd = status_counts.toPandas()\n",
    "\n",
    "# Sắp xếp giảm dần theo số lượng\n",
    "status_counts_pd = status_counts_pd.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Vẽ biểu đồ cột ngang\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(\n",
    "    y=\"loan_status\",\n",
    "    x=\"count\",\n",
    "    hue=\"loan_status\",       \n",
    "    data=status_counts_pd,\n",
    "    palette=\"crest\",\n",
    "    dodge=False,            \n",
    ")\n",
    "\n",
    "# Thêm nhãn số lượng bên phải từng cột\n",
    "for index, row in status_counts_pd.iterrows():\n",
    "    plt.text(\n",
    "        row[\"count\"] + 2000,\n",
    "        index,\n",
    "        str(row[\"count\"]),\n",
    "        va=\"center\"\n",
    "    )\n",
    "\n",
    "# Tiêu đề và nhãn\n",
    "plt.title(\"Phân bố trạng thái các khoản vay\", fontsize=14)\n",
    "plt.xlabel(\"Số lượng khoản vay\")\n",
    "plt.ylabel(\"Trạng thái khoản vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabcc88-2688-464b-b40d-029332c10068",
   "metadata": {},
   "source": [
    "## Trung bình số dư gốc theo trạng thái"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f5fe9-7d8f-4134-b064-05eb134f2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_out_prncp = (\n",
    "    loan_status_history_df.groupBy(\"loan_status\")\n",
    "      .agg(avg(\"out_prncp\").alias(\"avg_out_prncp\"))\n",
    "      .orderBy(col(\"avg_out_prncp\").desc())\n",
    ")\n",
    "avg_out_prncp.show()\n",
    "avg_out_prncp_pd = avg_out_prncp.toPandas()\n",
    "\n",
    "avg_out_prncp_pd = avg_out_prncp_pd.sort_values(by=\"avg_out_prncp\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(30, 6))\n",
    "sns.barplot(\n",
    "    y=\"loan_status\",\n",
    "    x=\"avg_out_prncp\",\n",
    "    hue=\"loan_status\",     \n",
    "    data=avg_out_prncp_pd,\n",
    "    palette=\"viridis\",\n",
    "    dodge=False\n",
    ")\n",
    "\n",
    "for index, row in avg_out_prncp_pd.iterrows():\n",
    "    plt.text(\n",
    "        row[\"avg_out_prncp\"] + 100, \n",
    "        index,\n",
    "        f\"{row['avg_out_prncp']:.2f}\",\n",
    "        va=\"center\"\n",
    "    )\n",
    "\n",
    "# Tiêu đề và nhãn\n",
    "plt.title(\"Trung bình dư nợ gốc (Outstanding Principal) theo trạng thái khoản vay\", fontsize=14)\n",
    "plt.xlabel(\"Giá trị trung bình dư nợ gốc (avg_out_prncp)\")\n",
    "plt.ylabel(\"Trạng thái khoản vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b80d5f-865a-40bc-a2a1-f9ac2cb80085",
   "metadata": {},
   "source": [
    "##  Kế hoạch trả góp (pymnt_plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92788b5b-2013-44bf-a059-682966fc6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_counts = loan_status_history_df.groupBy(\"pymnt_plan\").agg(count(\"*\").alias(\"count\"))\n",
    "plan_counts.show()\n",
    "plan_pd = plan_counts.toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9460b-1295-418a-b472-7dd07e47b7d6",
   "metadata": {},
   "source": [
    "## Trung bình gốc còn lại theo kế hoạch trả góp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee2ba4-3a4e-4307-bd97-e7e59bf73bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_principal_plan = (\n",
    "    loan_status_history_df.groupBy(\"pymnt_plan\")\n",
    "      .agg(avg(\"out_prncp\").alias(\"avg_remaining_principal\"))\n",
    ")\n",
    "avg_principal_plan.show()\n",
    "avg_principal_pd = avg_principal_plan.toPandas()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.barplot(\n",
    "    x=\"pymnt_plan\",\n",
    "    y=\"avg_remaining_principal\",\n",
    "    hue=\"pymnt_plan\",\n",
    "    data=avg_principal_pd,\n",
    "    palette=\"pastel\",\n",
    "    dodge=False\n",
    ")\n",
    "\n",
    "for index, row in avg_principal_pd.iterrows():\n",
    "    plt.text(\n",
    "        x=index,\n",
    "        y=row[\"avg_remaining_principal\"] + 200,\n",
    "        s=f\"{row['avg_remaining_principal']:.0f}\",\n",
    "        ha=\"center\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Số dư gốc trung bình theo kế hoạch thanh toán (pymnt_plan)\")\n",
    "plt.xlabel(\"Kế hoạch thanh toán\")\n",
    "plt.ylabel(\"Số dư gốc trung bình\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa75a7-6e17-4bce-be51-b2a0fa68ddc3",
   "metadata": {},
   "source": [
    "## Tỷ lệ mức được giải ngân (funded_amnt / loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c76747-cd00-4a81-a0f8-4d8736f1bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df1 = loan_df.withColumn(\n",
    "    \"funded_ratio\",\n",
    "    col(\"funded_amnt\") / col(\"loan_amnt\")\n",
    ")\n",
    "\n",
    "pd1 = df1.select(\"funded_ratio\").toPandas().dropna()\n",
    "\n",
    "median1 = pd1[\"funded_ratio\"].median()\n",
    "\n",
    "ratio_1 = (pd1[\"funded_ratio\"] == 1.0).mean()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "ax = sns.histplot(pd1[\"funded_ratio\"], bins=50, kde=True)\n",
    "\n",
    "plt.axvline(median1, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "ymax = ax.get_ylim()[1]\n",
    "plt.text(\n",
    "    median1,\n",
    "    ymax * 0.95,\n",
    "    f\"Trung vị = {median1:.2f}\",\n",
    "    color=\"red\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "if ratio_1 > 0.90:\n",
    "    plt.xlim(0.90, 1.01)\n",
    "\n",
    "plt.title(\"Phân phối funded_ratio (tỷ lệ mức được giải ngân)\", fontsize=18)\n",
    "plt.xlabel(\"funded_ratio (funded_amnt / loan_amnt)\", fontsize=14)\n",
    "plt.ylabel(\"Số lượng mẫu\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69648460-1382-4ff4-8e44-33639bfad60d",
   "metadata": {},
   "source": [
    "## Giá trị khoản vay (installment / loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f8621-b6e2-48bd-9de8-4aae7e2d70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df2 = loan_df.withColumn(\n",
    "    \"installment_to_loan_ratio\",\n",
    "    col(\"installment\") / col(\"loan_amnt\")\n",
    ").withColumn(\n",
    "    \"loan_bucket\",\n",
    "    when(col(\"loan_amnt\") < 5000, \"<5 triệu\")\n",
    "    .when(col(\"loan_amnt\") < 10000, \"5–10 triệu\")\n",
    "    .when(col(\"loan_amnt\") < 15000, \"10–15 triệu\")\n",
    "    .otherwise(\"15 triệu+\")\n",
    ")\n",
    "\n",
    "pd2 = df2.select(\"installment_to_loan_ratio\", \"loan_bucket\").toPandas().dropna()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(\n",
    "    x=\"loan_bucket\",\n",
    "    y=\"installment_to_loan_ratio\",\n",
    "    data=pd2,\n",
    "    palette=\"pastel\"\n",
    ")\n",
    "\n",
    "plt.title(\"Tỷ lệ trả góp / khoản vay theo từng nhóm giá trị khoản vay\", fontsize=16)\n",
    "plt.xlabel(\"Nhóm giá trị khoản vay\", fontsize=14)\n",
    "plt.ylabel(\"Tỷ lệ trả góp trên khoản vay\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc01e9-0a3a-4f2c-87a8-b79229b13272",
   "metadata": {},
   "source": [
    "## Phân phối tiền lãi trả theo từng hạng tín dụng ( int_rate * 100 / loan_amnt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c6bf0-c354-4195-bb8c-3a2a32658d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df3 = loan_df.withColumn(\n",
    "    \"interest_per_dollar\",\n",
    "    (col(\"int_rate\") / 100) * col(\"loan_amnt\")\n",
    ")\n",
    "\n",
    "pd3 = df3.select(\"interest_per_dollar\", \"grade\").toPandas().dropna()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(\n",
    "    x=\"grade\",\n",
    "    y=\"interest_per_dollar\",\n",
    "    data=pd3,\n",
    "    palette=\"pastel\"\n",
    ")\n",
    "\n",
    "plt.title(\"Phân phối tiền lãi phải trả theo từng hạng tín dụng (grade)\", fontsize=16)\n",
    "plt.xlabel(\"Hạng tín dụng (Grade)\", fontsize=14)\n",
    "plt.ylabel(\"Số tiền lãi phải trả\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914b398-c18b-46ab-abda-f90e5ffccfbb",
   "metadata": {},
   "source": [
    "## Mật độ phân phối khoản vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3a2ac-e356-45bd-8144-d37322f5b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd4 = loan_df.select(\"loan_amnt\").toPandas().dropna()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "sns.kdeplot(pd4[\"loan_amnt\"], fill=True)\n",
    "\n",
    "peak = pd4[\"loan_amnt\"].mode()[0]\n",
    "plt.axvline(peak, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.text(peak, plt.ylim()[1]*0.8, f\"mode = {peak}\", color=\"red\")\n",
    "\n",
    "plt.title(\"Mật độ phân phối khoản vay (Loan Amount)\")\n",
    "plt.xlabel(\"Khoản vay (loan_amnt)\")\n",
    "plt.ylabel(\"Mật độ (Density)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e80cf-296a-4698-8e2b-dbc2ad3a2205",
   "metadata": {},
   "source": [
    "# 4. Repayment_summary: Tổng hợp trả nợ vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a96257-0cf0-4c69-b4b9-e3c3b6d67e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"RepaymentSummaryAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25ca28-a042-4f6a-8623-35826e20f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "repayment_summary_df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/bigdata/data/splitted_data/repayment_summary\",\n",
    "    header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ac02c-f5ae-43fd-8507-81682c06406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repayment_summary_df.printSchema()\n",
    "repayment_summary_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26723a-1d89-44c8-a94a-56a7dedbec91",
   "metadata": {},
   "source": [
    "## Thống kê tổng quát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cca50a-73ac-46c2-9a79-556b732062f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, round, min as _min, max as _max, stddev\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a06e31-78a3-4703-ab93-63189cb1bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = repayment_summary_df.select(\n",
    "    round(avg(\"total_pymnt\"), 2).alias(\"mean_total_pymnt\"),\n",
    "    round(stddev(\"total_pymnt\"), 2).alias(\"std_total_pymnt\"),\n",
    "    _min(\"total_pymnt\").alias(\"min_total_pymnt\"),\n",
    "    _max(\"total_pymnt\").alias(\"max_total_pymnt\"),\n",
    "    round(avg(\"total_rec_prncp\"), 2).alias(\"mean_principal\"),\n",
    "    round(avg(\"total_rec_int\"), 2).alias(\"mean_interest\"),\n",
    "    round(avg(\"recoveries\"), 2).alias(\"mean_recoveries\"),\n",
    "    round(avg(\"total_rec_late_fee\"), 2).alias(\"mean_late_fee\")\n",
    ").toPandas()\n",
    "\n",
    "print(\"\\n=== 📊 Thống kê tổng quan ===\")\n",
    "print(summary_stats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e5fd3-52c3-456e-a2e4-62beb380621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = [\n",
    "    \"total_pymnt\", \"total_rec_prncp\", \"total_rec_int\",\n",
    "    \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\"\n",
    "]\n",
    "numeric_pd = repayment_summary_df.select(*numeric_cols).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecb673-f53d-45b7-909b-548295ac3cdd",
   "metadata": {},
   "source": [
    "## Phân phối tổng tiền trả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3887be0-3c16-4e4b-9175-b9e100b155f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(numeric_pd[\"total_pymnt\"], bins=50, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Phân phối tổng tiền trả (Total Payment Distribution)\")\n",
    "plt.xlabel(\"Tổng tiền trả ($)\")\n",
    "plt.ylabel(\"Tần suất\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c0605-d690-4ae3-902b-bb840a6822d9",
   "metadata": {},
   "source": [
    "## Phân phối các chỉ số tài chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b099e75-b3a7-41ee-899b-f89978e00384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=numeric_pd, orient=\"h\", palette=\"pastel\")\n",
    "plt.title(\"Phân phối & ngoại lệ của các chỉ số tài chính\")\n",
    "plt.xlabel(\"Giá trị ($)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418196a1-e6d2-471d-a642-92df6fa095ac",
   "metadata": {},
   "source": [
    "## Trung bình gốc và lãi thu được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db0333-5b61-44eb-a469-856301606cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_principal_interest = repayment_summary_df.agg(\n",
    "    round(avg(\"total_rec_prncp\"), 2).alias(\"avg_principal\"),\n",
    "    round(avg(\"total_rec_int\"), 2).alias(\"avg_interest\")\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.barplot(\n",
    "    x=[\"Principal\", \"Interest\"], \n",
    "    y=[avg_principal_interest[\"avg_principal\"][0], avg_principal_interest[\"avg_interest\"][0]],\n",
    "    color=\"lightblue\"  \n",
    ")\n",
    "plt.title(\"Trung bình gốc & lãi thu được\")\n",
    "plt.ylabel(\"Giá trị trung bình ($)\")\n",
    "for i, v in enumerate([avg_principal_interest[\"avg_principal\"][0], avg_principal_interest[\"avg_interest\"][0]]):\n",
    "    plt.text(i, v + 0.05*v, f\"{v:,.0f}\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde3473-ffba-4d39-a935-538f259a1d4f",
   "metadata": {},
   "source": [
    "## Hiệu quả hoàn trả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc688eb-f191-4bee-ae45-16efab584d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repayment_summary_df = repayment_summary_df.withColumn(\n",
    "    \"repayment_efficiency\",\n",
    "    round(col(\"total_rec_prncp\") / col(\"total_pymnt\"), 3)\n",
    ")\n",
    "\n",
    "efficiency_bins = (\n",
    "    repayment_summary_df\n",
    "    .withColumn(\"efficiency_range\",\n",
    "        (col(\"repayment_efficiency\")*10).cast(\"int\")/10\n",
    "    )\n",
    "    .groupBy(\"efficiency_range\")\n",
    "    .count()\n",
    "    .orderBy(\"efficiency_range\")\n",
    ")\n",
    "\n",
    "efficiency_pd = efficiency_bins.toPandas()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(\n",
    "    x=\"efficiency_range\",\n",
    "    y=\"count\",\n",
    "    data=efficiency_pd,\n",
    "    color=\"skyblue\"\n",
    ")\n",
    "plt.title(\"Phân phối hiệu quả hoàn trả (Principal/Total Payment)\")\n",
    "plt.xlabel(\"Hiệu quả hoàn trả\")\n",
    "plt.ylabel(\"Số lượng khoản vay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27dea6b-be28-46a7-85aa-fa64946f6007",
   "metadata": {},
   "source": [
    "## Tương quan recoveries và collection recovery fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2b6d2-08cb-4971-bac8-2992309a9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recoveries_pd = repayment_summary_df.select(\n",
    "    \"recoveries\", \"collection_recovery_fee\"\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(\n",
    "    data=recoveries_pd,\n",
    "    x=\"recoveries\",\n",
    "    y=\"collection_recovery_fee\",\n",
    "    alpha=0.6,\n",
    "    color=\"purple\"\n",
    ")\n",
    "plt.title(\"Quan hệ giữa Recoveries và Collection Recovery Fee\")\n",
    "plt.xlabel(\"Recoveries ($)\")\n",
    "plt.ylabel(\"Collection Recovery Fee ($)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960de53-64a6-4412-b9d5-67ec8768658f",
   "metadata": {},
   "source": [
    "## Ma trận tương quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6248b-1a61-40e6-abea-887c96a59e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_pd = repayment_summary_df.select(\n",
    "    \"total_pymnt\", \"total_rec_prncp\", \"total_rec_int\",\n",
    "    \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\",\n",
    "    \"repayment_efficiency\"\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.heatmap(corr_pd.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Ma trận tương quan giữa các chỉ số tài chính\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c7215-207d-41fd-b035-67825587e27a",
   "metadata": {},
   "source": [
    "# 5. Credit profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b7134-5937-4538-8c3d-3dd87e15de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, datediff, current_date, to_date, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096760aa-304c-4b25-a810-fc47e06014a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"CreditProfileAnalysis\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12914a16-ac3c-47a1-9ba4-6534d41b444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/bigdata/data/splitted_data/credit_profile\", \n",
    "    header=True\n",
    ")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e54af5-224f-48f8-baa4-68b363ae536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ad297-d84b-4e46-946e-4633537a6190",
   "metadata": {},
   "source": [
    "## Tương quan các biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916d5f7-9ca1-435b-8d91-d3fb4b9792fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [c for c, t in df.dtypes if t in ('int', 'double')]\n",
    "pdf_corr = df.select(numeric_cols).toPandas().corr()\n",
    "\n",
    "df_corr = spark.createDataFrame(\n",
    "    pdf_corr.reset_index().melt(id_vars='index', var_name='variable', value_name='correlation')\n",
    ").withColumnRenamed('index','feature')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(pdf_corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title(\"Tương quan giữa các biến tín dụng chính\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ea70e-1b40-4096-aa98-e9c0ce9bf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_vn = {\n",
    "    \"delinq_2yrs\": \"Số lần trễ hạn 2 năm gần nhất\",\n",
    "    \"inq_last_6mths\": \"Số lần hỏi tín dụng 6 tháng gần nhất\",\n",
    "    \"mths_since_last_delinq\": \"Số tháng kể từ lần trễ hạn gần nhất\",\n",
    "    \"mths_since_last_record\": \"Số tháng kể từ ghi nhận rủi ro gần nhất\",\n",
    "    \"open_acc\": \"Số tài khoản mở\",\n",
    "    \"pub_rec\": \"Số hồ sơ công khai tiêu cực\",\n",
    "    \"revol_bal\": \"Số dư tín dụng quay vòng\",\n",
    "    \"revol_util\": \"Tỷ lệ sử dụng hạn mức tín dụng (%)\",\n",
    "    \"total_acc\": \"Tổng số tài khoản\",\n",
    "    \"collections_12_mths_ex_med\": \"Số collection 12 tháng gần nhất (ngoại trừ y tế)\",\n",
    "    \"mths_since_last_major_derog\": \"Số tháng kể từ vi phạm tín dụng nghiêm trọng gần nhất\"\n",
    "}\n",
    "\n",
    "numeric_cols = list(col_vn.keys())\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.histplot(pdf[col_name].dropna(), bins=30, kde=True, color=\"skyblue\")\n",
    "    plt.title(f\"Phân bố {col_vn[col_name]}\")\n",
    "    plt.xlabel(col_vn[col_name])\n",
    "    plt.ylabel(\"Số lượng khách hàng\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c42bd0-c1a0-4b1b-a35b-77b6cf295312",
   "metadata": {},
   "source": [
    "## Phân phối nhóm tài khoản sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c604f-3580-4129-8046-4c89ed726ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_distribution = df.withColumn(\n",
    "    \"Nhóm_tỷ_lệ_sử_dụng\", \n",
    "    when(col(\"revol_util\") < 20, \"0-20%\")\n",
    "    .when(col(\"revol_util\") < 40, \"20-40%\")\n",
    "    .when(col(\"revol_util\") < 60, \"40-60%\")\n",
    "    .when(col(\"revol_util\") < 80, \"60-80%\")\n",
    "    .otherwise(\"80-100%\")\n",
    ").withColumn(\n",
    "    \"Nhóm_số_tài_khoản\",   \n",
    "    when(col(\"open_acc\") < 5, \"Dưới 5\")\n",
    "    .when(col(\"open_acc\") < 10, \"5-10\")\n",
    "    .otherwise(\"Trên 10\")\n",
    ")\n",
    "\n",
    "pdf_dist = df_distribution.toPandas()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.countplot(x=\"Nhóm_tỷ_lệ_sử_dụng\", data=pdf_dist,\n",
    "              order=[\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"])\n",
    "plt.title(\"Phân phối nhóm theo tỷ lệ sử dụng tín dụng\")\n",
    "plt.xlabel(\"Tỷ lệ sử dụng hạn mức (%)\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"Nhóm_số_tài_khoản\", data=pdf_dist,\n",
    "              order=[\"Dưới 5\",\"5-10\",\"Trên 10\"])\n",
    "plt.title(\"Phân phối theo số lượng tài khoản mở\")\n",
    "plt.xlabel(\"Nhóm tài khoản\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591352d2-9e16-4a6b-ad8f-fb86f6810b13",
   "metadata": {},
   "source": [
    "## Tỉ lệ rủi ro theo nhóm tỷ lệ sử dụng tín dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680c0e9-9863-417d-b156-b2d69f4c593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behavior_risk = df.withColumn(\n",
    "    \"Cờ_rủi_ro\",\n",
    "    when(col(\"delinq_2yrs\") > 0, 1).otherwise(0)\n",
    ").withColumn(\n",
    "    \"Nhóm_tỷ_lệ_sử_dụng\",\n",
    "    when(col(\"revol_util\") < 20, \"0-20%\")\n",
    "    .when(col(\"revol_util\") < 40, \"20-40%\")\n",
    "    .when(col(\"revol_util\") < 60, \"40-60%\")\n",
    "    .when(col(\"revol_util\") < 80, \"60-80%\")\n",
    "    .otherwise(\"80-100%\")\n",
    ")\n",
    "\n",
    "pdf_risk = df_behavior_risk.groupBy(\"Nhóm_tỷ_lệ_sử_dụng\") \\\n",
    "    .agg((mean(\"Cờ_rủi_ro\") * 100).alias(\"Tỷ_lệ_rủi_ro_%\")) \\\n",
    "    .orderBy(\"Nhóm_tỷ_lệ_sử_dụng\") \\\n",
    "    .toPandas()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(\n",
    "    x=\"Nhóm_tỷ_lệ_sử_dụng\",\n",
    "    y=\"Tỷ_lệ_rủi_ro_%\",\n",
    "    data=pdf_risk,\n",
    "    order=[\"0-20%\",\"20-40%\",\"40-60%\",\"60-80%\",\"80-100%\"],\n",
    "    color=\"skyblue\"\n",
    ")\n",
    "plt.title(\"Tỷ lệ rủi ro theo nhóm tỷ lệ sử dụng tín dụng\")\n",
    "plt.xlabel(\"Nhóm tỷ lệ sử dụng hạn mức (%)\")\n",
    "plt.ylabel(\"Xác suất trễ hạn (%)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c0627-a298-4d30-baf1-f1d8e5399686",
   "metadata": {},
   "source": [
    "## Phân khúc khách hàng theo mức độ rủi ro tín dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51587dfe-09e8-4b9d-a1a0-b523335581b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_segments = df.withColumn(\n",
    "    \"Phân_khúc\", \n",
    "    when((col(\"revol_util\") < 30) & (col(\"delinq_2yrs\")==0), \"Rủi ro thấp\")\n",
    "    .when((col(\"revol_util\") < 60) & (col(\"delinq_2yrs\") <= 1), \"Rủi ro trung bình\")\n",
    "    .otherwise(\"Rủi ro cao\")\n",
    ")\n",
    "\n",
    "pdf_seg = df_segments.toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"Phân_khúc\", data=pdf_seg,\n",
    "              order=[\"Rủi ro thấp\", \"Rủi ro trung bình\", \"Rủi ro cao\"],\n",
    "              color=\"skyblue\")\n",
    "plt.title(\"Phân khúc khách hàng theo mức độ rủi ro tín dụng\")\n",
    "plt.xlabel(\"Nhóm khách hàng\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0fb19-0b8c-46a0-a196-89136e0a415e",
   "metadata": {},
   "source": [
    "# 6.Credit account detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39840c3f-ec6b-4f8e-9c87-2105985c1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"CreditAccountAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15352c5-0f33-4f45-b32f-835cbfc761b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "df = spark.read.csv(\"hdfs://namenode:9000/bigdata/data/splitted_data/credit_account_detail.csv\", \n",
    "                           header=True, inferSchema=True)\n",
    "\n",
    "print(\"Credit Account Detail schema:\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003598c-d368-4b22-a516-3da4a6e8bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_vn = {\n",
    "    \"open_acc_6m\": \"Số tài khoản mở trong 6 tháng\",\n",
    "    \"open_il_6m\": \"Số khoản vay trả góp mở 6 tháng\",\n",
    "    \"open_il_12m\": \"Số khoản vay trả góp mở 12 tháng\",\n",
    "    \"open_il_24m\": \"Số khoản vay trả góp mở 24 tháng\",\n",
    "    \"mths_since_rcnt_il\": \"Số tháng từ khoản vay trả góp gần nhất\",\n",
    "    \"total_bal_il\": \"Tổng dư nợ vay trả góp\",\n",
    "    \"il_util\": \"Tỷ lệ sử dụng tín dụng vay trả góp (%)\",\n",
    "    \"open_rv_12m\": \"Số tài khoản quay vòng mở 12 tháng\",\n",
    "    \"open_rv_24m\": \"Số tài khoản quay vòng mở 24 tháng\",\n",
    "    \"max_bal_bc\": \"Số dư cao nhất của thẻ tín dụng\",\n",
    "    \"all_util\": \"Tỷ lệ sử dụng tổng tín dụng (%)\",\n",
    "    \"total_rev_hi_lim\": \"Tổng hạn mức tín dụng cao nhất\",\n",
    "    \"tot_coll_amt\": \"Tổng số tiền bị thu hồi\",\n",
    "    \"tot_cur_bal\": \"Tổng dư nợ hiện tại\",\n",
    "    \"inq_fi\": \"Số lần hỏi tín dụng tài chính gần đây\",\n",
    "    \"total_cu_tl\": \"Tổng số tài khoản tín dụng hợp nhất\",\n",
    "    \"inq_last_12m\": \"Số lần hỏi tín dụng 12 tháng gần nhất\"\n",
    "}\n",
    "\n",
    "pdf = df.select(*col_vn.keys()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3e6cf-3eee-4fef-bb71-809cac07ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col_label in col_vn.items():\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.histplot(pdf[col_name].dropna(), bins=30, kde=True, color=\"skyblue\")\n",
    "    plt.title(f\"Phân bố {col_label}\")\n",
    "    plt.xlabel(col_label)\n",
    "    plt.ylabel(\"Số lượng khách hàng\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5497d9-091a-4572-96d7-9b059cf49d9b",
   "metadata": {},
   "source": [
    "## Ma trận tương quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1737f3e-31f0-4269-90cd-6aa4954c9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_corr = pdf.corr(numeric_only=True)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(pdf_corr, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Ma trận tương quan giữa các biến tài khoản tín dụng\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513cfe8c-1c9f-433a-ba41-0c0abbaa78cf",
   "metadata": {},
   "source": [
    "## Tỉ lệ nợ trên hạn mức ( (total_bal_il + max_bal_bc)/total_rev_hi_lim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f71cc-d401-463e-86d6-4edd4a2b6e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_debt_ratio = df.withColumn(\n",
    "    \"Tỷ_lệ_nợ_trên_hạn_mức\",\n",
    "    (col(\"total_bal_il\") + col(\"max_bal_bc\")) / (col(\"total_rev_hi_lim\") + 1)\n",
    ")\n",
    "pdf_debt = df_debt_ratio.select(\"Tỷ_lệ_nợ_trên_hạn_mức\").toPandas()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(pdf_debt[\"Tỷ_lệ_nợ_trên_hạn_mức\"].dropna(), bins=30, kde=False, color=\"salmon\")\n",
    "plt.title(\"Tỷ lệ nợ trên hạn mức tín dụng (Histogram)\")\n",
    "plt.xlabel(\"Tỷ lệ nợ / hạn mức\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd42fda-0836-4606-acdf-334d59ec77df",
   "metadata": {},
   "source": [
    "## Hoạt động tín dụng gần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b5818-c6f2-4c4a-b581-b6466d9c917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent_activity = df.withColumn(\n",
    "    \"Hoạt_động_tín_dụng_gần\",\n",
    "    col(\"open_acc_6m\") + col(\"open_il_6m\") + col(\"inq_last_12m\")\n",
    ")\n",
    "\n",
    "pdf_recent = df_recent_activity.select(\"Hoạt_động_tín_dụng_gần\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(pdf_recent[\"Hoạt_động_tín_dụng_gần\"], bins=30, kde=True, color=\"orange\")\n",
    "plt.title(\"Chỉ số hoạt động tín dụng gần đây\")\n",
    "plt.xlabel(\"Tổng số hoạt động trong 6-12 tháng\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629d355-0d49-4067-a4fa-58f1020afdff",
   "metadata": {},
   "source": [
    "## Tỉ lệ nợ trên hạn mức ( (total_bal_il + max_bal_bc) /total_rev_hi_lim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78600ff5-697d-4043-9591-f7f1ad08b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debt_ratio = df.withColumn(\n",
    "    \"Tỷ_lệ_nợ_trên_hạn_mức\",\n",
    "    (col(\"total_bal_il\") + col(\"max_bal_bc\")) / (col(\"total_rev_hi_lim\") + 1)\n",
    ")\n",
    "\n",
    "pdf_debt = df_debt_ratio.select(\"Tỷ_lệ_nợ_trên_hạn_mức\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.histplot(pdf_debt[\"Tỷ_lệ_nợ_trên_hạn_mức\"].dropna(), bins=30, kde=True, color=\"salmon\")\n",
    "plt.title(\"Tỷ lệ nợ trên hạn mức tín dụng\")\n",
    "plt.xlabel(\"Tỷ lệ nợ / hạn mức\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350debc-0075-4f96-8471-e21cb9026c7d",
   "metadata": {},
   "source": [
    "## Nhóm sử dụng tín dụng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4633765-bf47-43c3-a6a2-334b9d386821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_band = df.withColumn(\n",
    "    \"Nhóm_sử_dụng_tín_dụng\",\n",
    "    when(col(\"all_util\") < 20, \"Thấp (<20%)\")\n",
    "    .when(col(\"all_util\") < 50, \"Trung bình (20-50%)\")\n",
    "    .when(col(\"all_util\") < 80, \"Cao (50-80%)\")\n",
    "    .otherwise(\"Rất cao (>80%)\")\n",
    ")\n",
    "\n",
    "pdf_util = df_util_band.groupBy(\"Nhóm_sử_dụng_tín_dụng\").count().toPandas()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"Nhóm_sử_dụng_tín_dụng\", y=\"count\", data=pdf_util,\n",
    "            order=[\"Thấp (<20%)\",\"Trung bình (20-50%)\",\"Cao (50-80%)\",\"Rất cao (>80%)\"],\n",
    "            color=\"skyblue\")\n",
    "plt.title(\"Phân nhóm khách hàng theo mức sử dụng tín dụng tổng thể\")\n",
    "plt.xlabel(\"Mức sử dụng tín dụng (%)\")\n",
    "plt.ylabel(\"Số lượng khách hàng\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
